{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies.\n",
    "import matplotlib\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:///open_university.sqlite\", echo=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "The plan is to just look at the interaction with the course material to see if the student will be able to predict if the student will pass or fail.\n",
    "\n",
    "Not including information about the background of the student (demographics) or the scores of the student assessments but include if they submit the assessments or not.\n",
    "\n",
    "We are going to filter out students that withdraw from the course before the start of the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_ds = engine.execute(text(\"\"\"\n",
    "SELECT sI.code_module, sI.code_presentation, sI.id_student, sI.final_result, sR.date_registration, sR.date_unregistration\n",
    "FROM studentInfo as sI\n",
    "LEFT JOIN studentRegistration as sR ON sI.id_student = sR.id_student\n",
    "WHERE NOT (sR.date_unregistration <= -11 AND sI.final_result = 'Withdrawn')\n",
    "\"\"\")).fetchall()\n",
    "student_df = pd.DataFrame(student_ds, columns=['code_module', 'code_presentation', 'id_student', 'final_result', 'date_registration', 'date_unregistration'])\n",
    "student_df = student_df.astype({'code_module':'string', 'code_presentation':'string', 'id_student':'string', 'final_result':'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(student_df)\n",
    "display(student_df.describe())\n",
    "display(student_df.nunique())\n",
    "display(student_df['final_result'].value_counts())\n",
    "student_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I removed students that Withdrew before 11 days before the presentation starts because they whould not have participated in the course.\n",
    "* It looks like out of the 27,295 students there were 36,388 registrations which means some students where registered more than once. Of all the registrations there where 11,592 unregistrations.\n",
    "* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_course_df = student_df.loc[student_df['date_unregistration'] <= -11].copy()\n",
    "display(bf_course_df.head())\n",
    "display(bf_course_df.describe())\n",
    "#display(student_df.loc[student_df['date_registration'].isnull()])\n",
    "bf_course_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need to add the Vle connected to Student Vle\n",
    "vle_ds = engine.execute(text(\"\"\"\n",
    "SELECT cast(vle.id_site as text), vle.code_module, vle.code_presentation, vle.activity_type, vle.week_from, vle.week_to, cast(sVle.id_student as text), sVle.date, SUM(sVLe.sum_click) as sum_click\n",
    "FROM vle\n",
    "LEFT JOIN studentVle AS sVle ON vle.id_site = sVle.id_site AND vle.code_presentation = sVle.code_presentation AND vle.code_module = sVle.code_module\n",
    "GROUP BY vle.code_module, vle.code_presentation, sVle.id_student\n",
    "\"\"\")).fetchall()\n",
    "vle_df = pd.DataFrame(vle_ds, columns=['id_site', 'code_module', 'code_presentation', 'activity_type', 'week_from', 'week_to', 'id_student', 'date', 'sum_click'])\n",
    "vle_df = vle_df.astype({'id_site':'string', 'code_module':'string', 'code_presentation':'string', 'activity_type':'string', 'id_student':'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(vle_df)\n",
    "display(vle_df.nunique())\n",
    "vle_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ass_ds = engine.execute(text(\"\"\"\n",
    "SELECT cast(sAss.id_student as text), ass.code_module, ass.code_presentation, cast(sAss.id_assessment as text), sAss.date_submitted, ass.date\n",
    "FROM studentAssessment as sAss\n",
    "LEFT JOIN assessments as ass ON sAss.id_assessment = ass.id_assessment\n",
    "\"\"\")).fetchall()\n",
    "\n",
    "assessment_df = pd.DataFrame(ass_ds, columns=['id_student', 'code_module', 'code_presentation', 'id_assessent', 'date_submitted', 'date'])\n",
    "display(assessment_df.describe())\n",
    "assessment_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_assessed = list(assessment_df['id_student'].unique())\n",
    "all_students = list(student_df['id_student'].unique())\n",
    "print(\"\"\"\n",
    "We are looking at the students that haven't haded in any assessments.\n",
    "* We don't want them to skew our data as they never participated.\n",
    "* There could be reasons but for the momst part the students either withdrew or failed.\n",
    "* over 75% had unregistered by the 27th day of the presetation.\n",
    "* It could only be assumed that the 2 that passed had prior learning or some other reason.\n",
    "\"\"\")\n",
    "display(f\"Number of students assessed/total students: {len(list(students_assessed))}/{len(list(all_students))}\")\n",
    "\n",
    "student_not_assessed_df = student_df[~student_df['id_student'].isin(students_assessed)].copy()\n",
    "display(student_not_assessed_df.nunique())\n",
    "display(student_not_assessed_df['final_result'].value_counts())\n",
    "display(student_not_assessed_df[['date_registration', 'date_unregistration']].describe())\n",
    "\n",
    "print(\"\"\"\n",
    "The Students that have been assessed.\n",
    "\"\"\")\n",
    "\n",
    "students_assessed_df = student_df[student_df['id_student'].isin(students_assessed)]\n",
    "display(students_assessed_df.nunique())\n",
    "display(students_assessed_df['final_result'].value_counts())\n",
    "display(students_assessed_df[['date_registration', 'date_unregistration']].describe())\n",
    "\n",
    "print(\"\"\"\n",
    "The Students that have been not been assessed but interacted.\n",
    "\"\"\")\n",
    "\n",
    "student_not_assessed_df = vle_df[~vle_df['id_student'].isin(students_assessed)].copy()\n",
    "display(student_not_assessed_df.nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.astype({'gender':'string', 'imd_band':'string', 'highest_education':'string', 'age_band':'string', 'region':'string', 'final_result':'string'})\n",
    "#df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.nunique())\n",
    "#display(df.value_counts(\"gender\"))\n",
    "#display(df.value_counts(\"imd_band\"))\n",
    "#display(df.value_counts(\"highest_education\"))\n",
    "#print(f\"A-Level is equivilent to high school cert, HE Qualification is level 1 ro 2 of University, \")\n",
    "#display(df.value_counts(\"age_band\"))\n",
    "#display(df.value_counts(\"num_of_prev_attempts\"))\n",
    "#display(df.value_counts(\"region\"))\n",
    "display(df.value_counts(\"final_result\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distinction is a higher form of pass\n",
    "# withdrawn would be a fail if the student would not complete the course both fail and withdrawn is a form of failure.\n",
    "# Possible to remove withdrawn\n",
    "df_edited = df.copy()\n",
    "df_edited[\"final_result\"] = df_edited[\"final_result\"].replace({'Distinction': 'Pass', 'Withdrawn': 'Fail'})\n",
    "df_edited[\"final_result\"] = df_edited[\"final_result\"].replace({'Pass': '1', 'Fail': '0'})\n",
    "df_edited = df_edited.astype({'day': 'float32', 'clicks': 'float32', 'num_of_prev_attempts': 'float32', 'final_result': 'float32'})\n",
    "display(df_edited[\"final_result\"].unique())\n",
    "display(df_edited.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edited = pd.get_dummies(df_edited)\n",
    "df_edited.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine pass and distinction\n",
    "# combine widthdrawn and fail\n",
    "X = df_edited.drop('final_result', axis=1).values\n",
    "y = df_edited['final_result'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "\n",
    "# X shape / input feature / columns rule of thumbs is normally 2-3 times the ammount so 43 * 2 or 3 is 86-129 so i will try choosing 90 for the first hidden node\n",
    "hidden_nodes1 = 90\n",
    "hidden_nodes2 = 60\n",
    "hidden_nodes3 = 30\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes1, input_shape=(number_input_features,), activation='relu'))\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes2, activation='relu'))\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes3, activation='relu'))\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save(\"models/Student_Pass1Fail_relu90+relu60+relu30+sigmoid.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the accuracy\n",
    "df_edited = pd.DataFrame(fit_model.history, index = range(1, len(fit_model.history['loss'])+1))\n",
    "df_edited.plot(y = 'accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
